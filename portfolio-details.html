<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>MNIST Data-Set</title>
  <meta name="Description" content="Analysis of the MNIST data set using a variational Autoencoder" >
  <meta name="Machine Learning" content="Variational Autoencoder" >

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/favicon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/profile-img2.jpg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Adam Paslawski</a></h1>
        <div class="social-links mt-3 ">
          <a href="linkedin.com/in/adam-paslawski-098b53162" class="linkedin"><i class="bx bxl-linkedin"></i></a>
        </div>
      </div>

      <nav class="nav-menu">
        <ul>
          <li class="active"><a href="index.html"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="index.html#about"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="index.html#resume"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="index.html#portfolio"><i class="bx bx-book-content"></i> Portfolio</a></li>
        </ul>
      </nav><!-- .nav-menu -->
      <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>
    </div>
  </header><!-- End Header -->
    <!-- ======= Hero Section ======= -->
    <section id="hero-p" class="hero-2 d-flex flex-column justify-content-center align-items-center">
      <div class="hero-container" data-aos="fade-in">
        <h1 class = "portfoli-title">Teaching a computer to Handwrite</h1>
      </div>
    </section><!-- End Hero -->

  <main id="main">
    <!-- ======= Report Begins Here======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">
        <!-- OVERVIEW -->
        <div class="portfolio-description">
          <h1 class = "col-lg-12">Overview</h1>
          <p class = "col-lg-12">
            The MNIST data set is a collection of about 70,000 28x28 pixel images of handwritten digits like the one below.
          </p>
          <div class="row" data-aos="fade-left">
            <div class="container ">
              <img class = "col-lg-12 square-img" src="assets/img/portfolio/vae/entire9.png" alt="">
            </div>
            <p class = "col-lg-12">
              The goal of the project is to use a variational autoencoder to learn from this data and create a latent distribution from which we can draw samples from and sample handwritten digits.
            </p>
          </div>
          <div class="row" data-aos="fade-left">
            <h5 class = "col-lg-12" >Disclaimer</h5>
            <p class = "col-lg-12">
              The techniques used in this project were done in the a course called Statistics
               for Machine Learning taught by <a href="http://www.cs.toronto.edu/~duvenaud/">David Duvenaud</a>
              and <a href="http://www.jessebett.com/">Jesse Bettencourt</a> and based on the paper <a href="https://arxiv.org/pdf/1312.6114.pdf">Auto-Encoding Variational Bayes
              </a>.
            </p>
            <p class = "col-lg-12">Now that credit has been given where it is most certainly due, lets get into it!</p>
          </div>
          <div class="row" data-aos="fade-left">
            <h1 class = "col-lg-12">The first obvious question:</br><em>"What the heck is a variational autoencoder?"</em></h1>
            <p class = "col-lg-12">A variational autoencoder has two pieces:</p>
            <ol class = "col-lg-12">
              <li>encoder</li>
              <li>decoder</li>
            </ol>
          </div>
        </div>


        <!-- Encoder section -->
        <div class="portfolio-description">
          <div class="row" data-aos ="fade-left">
            <h1 class = "col-lg-12">The Encoder</h1>
            <p class = "col-lg-12">The Encoder takes a 28x28 pixel image and transforms those pixels with some fancy math to produce a latent representation of that image.</p>
            <p class = "col-lg-12">If you're not sure what <em>latent version</em> is, thats fine just think of it as a much smaller condensed version of the image, for this case were going from 784 dimensions  (784 pixels) down to a mean and standard deviation for a normal distribution.</p>
            <div class="container ">
              <img  class = "horrizontal-img col-lg-12" src="assets/img/portfolio/vae/encoder.png" alt="Encoder Network">
            </div>
            <p class = "col-lg-12">Implemented like this:</p>
            <div class="container ">
              <pre>
                <code>
def neural_net_predict(params, inputs):
"""Params is a list of (weights, bias) tuples.
  inputs is an (N x D) matrix.
  Applies batch normalization to every layer but the last."""
for W, b in params:
    outputs = np.dot(inputs, W) + b  # linear transformation
    inputs = np.tanh(outputs)           # nonlinear transformation
return outputs

def nn_predict_gaussian(params, inputs):
  #Returns means and diagonal variances
  return unpack_gaussian_params(neural_net_predict(params, inputs))


def encoder(x , rec_params):
  return(nn_predict_gaussian(rec_params,x))
                </code> 
              </pre>
            </div>
        </div>



        <!-- Decoder section -->
        <div class="portfolio-description">
          <div class="row" data-aos ="fade-left">
            <h1 class = "col-lg-12">The Decoder</h1>
            <p class = "col-lg-12">The decoder does the opposite in a sense. It takes an encoding of an image and <em>decodes</em> it to generate an image.</p>
            <p class = "col-lg-12">So it take a latent representation of an image and transforms it into a 28x28 greyscale image.</p>
            <div class="container ">
              <img class = "horrizontal-img" src="assets/img/portfolio/vae/decoder.png" alt="Decoder network">
            </div>
            <p class = "col-lg-12">Implemented like this:</p>
            <div class="container ">
              <pre>
                <code>
def decoder(params,z):
  return(neural_net_predict(params,z))
                </code> 
              </pre>
            </div>
          </div>
        </div>


        <div class="portfolio-description ">
          <div class="row" data-aoe = "fade-left">
            <h1 class = " col-lg-12" >Well That was easy!</h1>
            <p class = "col-lg-12">Just kidding! If you encode and decode and image you should hope to get that same image back, but in the beginning we would get something like this!</p>
            <div class="container ">
              <img class = "col-lg-12 horrizontal-img" src="assets/img/portfolio/vae/decoder-foreal.jpg" alt="Encoder Decoder network producing noise">
            </div>
            <p class = "col-lg-12">Thats because the mathematical transformations are totally random and havent learned how to deconstruct and reconstruct these images ... yet.</p>
          </div>
        </div>

        <div class="portfolio-description">
          <div class="row" data-aoe = "fade-left">
            <h1 class = "col-lg-12">Training</h1>
            <p class = "col-lg-12">Just like great athletes , variational autoencoders need lots of training.</p>
            <p class = "col-lg-12">We will do this by trying to make sure when we deconstruct and reconstruct an image we get close to the same thing back.</p>
            <p class="col-lg-12">Mathematically we are maximizing a lower bound estimate of the loss which is outlined in <a href="https://arxiv.org/pdf/1312.6114.pdf">the paper this is based on.</a></p>
            <p class="col-lg-12">Implementing this in a scalable  way:</p>
            <div class="container ">
              <pre>
                <code>
  def vae_lower_bound(gen_params, rec_params, data, rs):
    # We use a simple Monte Carlo estimate of the KL
    # divergence from the prior.
    q_means, q_log_stds = encoder(data , rec_params)
    latents = sample_diag_gaussian(q_means , q_log_stds,npr.RandomState(0))
    log_q_z = diag_gaussian_log_density(latents,q_means,q_log_stds)
    log_prior_z = log_prior(latents)
    log_p_x_given_z = log_likelihood(gen_params, data, latents)
    joint = log_prior_z + log_p_x_given_z
    elbo_estimate = np.mean(joint - log_q_z)
    return elbo_estimate
                </code>
              </pre>
            </div>
          </div>
          <p class = "col-lg-12">Now if we compare original images with the generated version below we can see:</p>
          <div class="container ">
            <img class = "horrizontal-img", src="assets/img/portfolio/vae/2by10plot.png" alt="">
          </div>
          <p class="col-lg-12">They look remarkably similar, which means our model has been trained well!</p>
        </div>
        <div class="portfolio-description ">
          <div class="row" data-aoe = "fade-left">
            <h1 class="col-lg-12">Application</h1>
            <!-- Application 1 -->
            <h2 class = " col-lg-12" >1. Getting Our Computer to Handwrite</h1>
            <p class = "col-lg-12">One application of a variational autoencoder is using it to generate unseen data.</p>
            <div class="container ">
              <img class = "square-img" src="assets/img/portfolio/vae/entire9-generated.png" alt="Handwritten number 9">
            </div>
            <p class = "col-lg-12">So we have learned what a handwritten "9" looks like, sampled it from our latent distribution and decoded it to the image you see above using our decoder network.</p>
            <!-- Application 2 -->
            <h2 class = " col-lg-12" >2. Interpolating Between Handwritten Numbers.</h1>
            <p class = "col-lg-12">Since the digits "live" in  a latent space so we can interpolate between numbers and see how the model is understanding how digits are related.</p>
            <div class="container ">
              <img class = "horrizontal-img" src="assets/img/portfolio/vae/interpolation.png" alt="Handwritten number 9">
            </div>
            <!-- Application 3 -->
            <h2 class = " col-lg-12" >3. Predicting the bottom half of the image given the top</h1>
            <p class = "col-lg-12">Another application is generating the bottom half of the image given the top.</p>
            <p class="col-lg-12">This requires a little more work but is based on the exact same principles.</p>
            <!-- <img class = "square-img" src="assets/img/portfolio/vae/entire9-generated.png" alt="Handwritten number 9"> -->
          </div>
        </div>
      </div>
    </section>
    <!-- End Report -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">

  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>